# -*- coding: utf-8 -*-
"""SVM_Elec378FinalProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ApBTpL5P1haG6vNlKf6dIASpWypTfGQj
"""

import librosa
import numpy as np
import csv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import StratifiedKFold
from sklearn.decomposition import PCA

from google.colab import drive
drive.mount('/content/drive')

"""**Loading Kaggle Data**"""

def extract_features(file_name, start_second, duration=3):
    try:
        # Load a segment of the audio file
        audio_timeseries, sampling_rate = librosa.load(file_name, sr=None, offset=start_second, duration=duration)

        # Extract MFCC and other features
        mfccs = librosa.feature.mfcc(y=audio_timeseries, sr=sampling_rate, n_mfcc=20)
        chroma = librosa.feature.chroma_stft(y=audio_timeseries, sr=sampling_rate)
        contrast = librosa.feature.spectral_contrast(y=audio_timeseries, sr=sampling_rate)
        tonnetz = librosa.feature.tonnetz(y=audio_timeseries, sr=sampling_rate)
        all_features = np.vstack([mfccs, chroma, contrast, tonnetz])
        features_mean = np.mean(all_features, axis=1)
        return features_mean
    except Exception as e:
        print(f"Error loading {file_name}: {e}")
        return None

# Load labels from CSV
labels = []
with open('/content/drive/My Drive/Elec378 Final Project/Dataset/train.csv', mode='r', newline='', encoding='utf-8') as file:
    reader = csv.reader(file)
    next(reader)  # Skip the header
    for row in reader:
        labels.append(row[1])

# Load dataset and extract features
features = []
labels_for_features = []

# Duration and segments for splitting
total_duration = 30
segment_duration = 3
segments_per_file = total_duration // segment_duration

for i in range(len(labels)):
    file_name = f'/content/drive/My Drive/Elec378 Final Project/Dataset/train/train{str(i).zfill(3)}.wav'
    for j in range(segments_per_file):
        start_second = j * segment_duration
        mfccs = extract_features(file_name, start_second, duration=segment_duration)
        if mfccs is not None:
            features.append(mfccs)
            # Each segment gets the same label
            labels_for_features.append(labels[i])

# Convert to numpy arrays and continue as before
features = np.array(features)
labels_for_features = np.array(labels_for_features)
label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(labels_for_features)

# Convert to numpy arrays and continue as before
features = np.array(features)
labels_for_features = np.array(labels_for_features)
label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(labels_for_features)

# Initialize cross-validation
kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)
accuracies = []

# SVM Model and preprocessing initialization
svm_clf = SVC(kernel='rbf', C=1, gamma='auto')
scaler = StandardScaler()
pca = PCA(n_components=0.95)

# Perform cross-validation
for train_index, test_index in kf.split(features, labels_encoded):
    X_train, X_test = features[train_index], features[test_index]
    y_train, y_test = labels_encoded[train_index], labels_encoded[test_index]
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    X_train_pca = pca.fit_transform(X_train_scaled)
    X_test_pca = pca.transform(X_test_scaled)
    svm_clf.fit(X_train_pca, y_train)
    y_pred = svm_clf.predict(X_test_pca)
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)

average_accuracy = np.mean(accuracies)
print(f"Average Accuracy: {average_accuracy * 100:.2f}%")

"""Actual Test Data"""

# Prepare to extract and predict for test data
test_features = []
segment_duration = 3
segments_per_file = 10

for i in range(200):  # Assuming 200 test files
    file_name = f'/content/drive/My Drive/Elec378 Final Project/Dataset/test/test{str(i).zfill(3)}.wav'
    for j in range(segments_per_file):
        start_second = j * segment_duration
        mfccs = extract_features(file_name, start_second, duration=segment_duration)
        if mfccs is not None:
            #2D array shape
            test_features.append(mfccs.reshape(1, -1))

# Convert list of arrays into a single numpy array
test_features = np.vstack(test_features)
test_scaled = scaler.transform(test_features)
test_pca = pca.transform(test_scaled)

# Predict using the SVM (with decoded predictions)
test_pred = svm_clf.predict(test_pca)
test_pred_labels = label_encoder.inverse_transform(test_pred)

# Determine most common predictions
final_predictions = []
for i in range(200):
    start_index = i * segments_per_file
    end_index = start_index + segments_per_file
    segment_labels_encoded = label_encoder.transform(test_pred_labels[start_index:end_index])

    # Calculate the most common label predicted across all segments of this file
    most_common_label_index = np.bincount(segment_labels_encoded).argmax()
    most_common_label = label_encoder.classes_[most_common_label_index]
    final_predictions.append(most_common_label)

# CSV
with open('svm.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['ID', 'Genre'])
    for i, genre in enumerate(final_predictions):
        writer.writerow([f'test{str(i).zfill(3)}.wav', genre])
